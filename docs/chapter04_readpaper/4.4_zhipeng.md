



# 4.4 张志鹏两个主要的github详解



交流记录：

```
1.vital
模板更新一定中不了，motivation太差，别人已经做过的
不是纯transformer，只是在siamese边缘弄了一部分transformer,vit整个都是transformer，但跟踪里没有
transformer在小的数据集上训练效果不如正常的卷积，但跟踪本来很麻烦，如果用大的数据集训练根本训不了，如果能推翻，就是如果用transformer不用大数据还能刷过cnn，相当于推翻了一个别人的结论

detr还是可以用的，产生一堆候选框，本质跟cv没有区别，遮挡：上下文的推理或re检测
解决遮挡就只有siamrcnn，通过reid做，在long-term上刷的点很高，解决目标丢失的问题，

如果想做更新的话就不能仅仅更新模板，得考虑一个比较全面的东西，如果仅仅换一个方法，意义不大，或者更新模板+参数，siamese里面没有真正的一篇文章，做在线更新的，现在在线更新用的都是atom的那一套架构，但即使是更新参数的siamese，听起来也不吸引人了，因为前几年很多人都提到了这个问题，之前ocean也把dimp强行拼上，motivation指的是别人没有看到过的东西，

transformer行，但是下手要快，很多人都在做，如果要做个好的，就要想的更全面一些，比如backbone换成transformer，match换transformer,估计那一块换detr，detr不好训练，detr更新了一些文章，整个都是transformer还是有意义的，从头到尾一个卷积都没有，分类，回归+backbone那一块，都没有卷积的话其实还是有意义的，
vit就是这样的，把输入图像变成了patch，跟卷积没有什么区别，出来也是n*n的featuremap，后面做分类，回归，其实没有区别，
之前做了一个实验，把vit的backbone拿过来，在跟踪上训练一下，看性能怎么样，
一点一点研究，如果先换backbone看有没有效果，如果没有效果的话，为什么没有效果，应该怎么把这个效果改进，跟cnn能比得上，如果backbone搞定的话，后面就可以把分类回归换成transformer，然后transformer很占内存，vit那个架构不太占内存，我觉得还行，

binary的network，但实用的话边缘设备，
脉冲神经网络，做量化，
做量化，提升速度，
如果用在跟踪中，而且性能不降很多，也有意义，
```











## 4.4.1 SOTS

### 单目标跟踪

- OceanPlus
- Ocean
- SiamDW

### 多目标跟踪

- CSTrack

### 结果评估

### 结构

- `experiments:`trainging and testing settings
- `demo:` figures for readme
- `dataset:`testing dataset
- `data:`training dataset
- `lib:`core scripts for all trackers
- `snapshot:`pre-trained models
- `pretrain:`models trained on ImageNet (for training)
- `tutorials:` guidelines for training and testing
- `tracking:`training and testing interface

```
$TrackSeg
|-experiments
|-lib
|-snapshot
	|-xxx.model/xxx.pth
|-dataset
	|-VOT2019.json
	|-VOT2019
		|-ants1
	|-VOT2020
		|-ants1
```

