# 4.2 Soarkey's Blog

## 4.2.1 multi-stream conv-LSTM

![](..\img\chapter04\4.2_1.png)

**paper:**https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123670001.pdf

**no code**

**ECCV 2020**

---

### Abstract

预测目标的未来位置，3个关键点：

- object motion trajectory is affected significantly by camera motion;
- the past trajectory of an object can act as a salient cue to estimate the object motion in the spatial domain;
- previous frames contain the surroundings and appearance of the target object, which is useful for predicting the target object’s future locations.

 By combining **the heatmap scores** from our tracker (DiMP/ that utilises appearance inference) and **the locations of the target object** from our trajectory inference, we predict the final target’s location in each frame.

现有tracking方法存在的问题：不能很好地处理遮挡和区分多个外观相似的物体。

由3个子网络组成：

<font color=red>appearance-based</font> tracking network (tracker) + <font color=red>background-motion</font> prediction network + <font color=red>trajectory </font> prediction network

### 1. Related work

**future trajectory prediction:**

1. human social interactions and behaviours in crowd scene

2. decision-making process

3. rich features about human behavioural information + interaction with their surrounding

4. Scene-LSTM, divide static scene to Manhattan grid

5. SoPhie, deep-net features <-(from)- scene semantic segmentation model

    + GAN -(to)-> attention –> model person trajectory （用GAN的方式训练）

**motion prediction:**

1. RNN + 时间窗口联合推理多条线索 –> 用于计算similarity score

2. Gaussian process regression model –> pedestrian motion

3. statistically based model
   （以上三种方法都假定static camera，另一些方法consider motion as camera motion + object motion）

4. camera ego-motion scales + speed of target person + person pose –> predict person’s location

   以上方法都使用了目标背景信息(surroundings)，对单目标追踪泛化性能不好，

   本文只使用past trajectory + target visual features –> predict short-term future locations

### 2.Method

组成的三个部分：
![](..\img\chapter04\4.2_2.png)

**Tracker：**

 本文采用DiMP作为基准

**trajectory prediction network：**

 采用LSTM结构

![](..\img\chapter04\4.2_3.png)

**background motion prediction network：**

​	> 用Siamese网络比较background与相邻帧==【local movement】==

- 最高响应值点的位移
- 多尺度图片中得到旋转角度rtr_trt和尺度变换ctc_tct

![](..\img\chapter04\4.2_4.png)



​	> each frame with [t0−tprev,t0−1][t_0-t_{prev}, t_0-1][t0−tprev,t0−1]   【global movement】

- time-varying background motion pattern （随时间变化的运动模式）


![](..\img\chapter04\4.2_5.png)


![](..\img\chapter04\4.2_6.png)